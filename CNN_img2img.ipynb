{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyM2jg6gMw7bT81ksUgaFkD8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"RNe9O2YtVeR2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703190046434,"user_tz":-60,"elapsed":112213,"user":{"displayName":"Maria Tapia","userId":"08787929203323078025"}},"outputId":"f51bc7f0-c00f-443f-c0e5-c1bda69b6bdd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyts\n","  Downloading pyts-0.13.0-py3-none-any.whl (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.23.5)\n","Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.11.4)\n","Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.3.2)\n","Requirement already satisfied: numba>=0.55.2 in /usr/local/lib/python3.10/dist-packages (from pyts) (0.58.1)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.2->pyts) (0.41.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->pyts) (3.2.0)\n","Installing collected packages: pyts\n","Successfully installed pyts-0.13.0\n","Collecting keras-tuner\n","  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m857.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n","Collecting kt-legacy (from keras-tuner)\n","  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n","Installing collected packages: kt-legacy, keras-tuner\n","Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n","Mounted at /content/drive/\n","Mounted at /content/drive\n"]}],"source":["!pip install pyts\n","!pip install keras-tuner\n","import os\n","import sys\n","import torch\n","import random\n","import numpy as np\n","import pandas as pd\n","from uu import Error\n","import torch.nn as nn\n","from tqdm import trange\n","from torch import optim\n","import keras_tuner as kt\n","from datetime import datetime\n","from google.colab import drive\n","from scipy.fft import fft, ifft\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","from keras.optimizers import Adam\n","from keras.models import Sequential\n","from pyts.image import GramianAngularField\n","from keras_tuner.tuners import RandomSearch\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.model_selection import train_test_split\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.layers import InputLayer, LSTM, BatchNormalization, Conv2D, Dense, Flatten, MaxPooling2D, Dropout, Reshape, GRU\n","\n","drive.mount('/content/drive/')\n","project = '/content/drive/My Drive/final_project'\n","sys.path.append(project)\n","\n","from RICODataset import *\n","from aux_functions import *\n","\n","def plot_image(data, title, save_path, index):\n","    \"\"\"\n","    Function to visualize and save a single FFT image.\n","    :param data: 2D or 3D array representing the images.\n","    :param title: Title of the plot.\n","    :param save_path: Path to save the image.\n","    :param index: Index of the image to be plotted.\n","    \"\"\"\n","    plt.figure(figsize=(6, 6))\n","    if data.ndim == 4 and data.shape[3] == 1:  # Single-channel 3D data\n","        plt.imshow(data[index, :, :, 0], cmap='gray', origin='lower')\n","    elif data.ndim == 3:  # data is 2D\n","        plt.imshow(data[index], cmap='gray', origin='lower')\n","\n","    plt.title(title)\n","    f = data.shape[2]\n","    time = datetime.now().strftime(\"%d_%H%M\")\n","    plt.savefig(os.path.join(save_path, f'images/img2img_cnn/F{f}_Images'))\n","\n","\n","def transform_to_image(data):\n","    fft_data = fft(data, axis=1)\n","    image_data = np.abs(fft_data).reshape(data.shape[0], data.shape[1], -1, 1)\n","    return image_data\n","\n","# Function to display images\n","def display_images(images):\n","    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n","    for img, ax in zip(images, axes):\n","        ax.imshow(img.squeeze(), cmap='gray')\n","        ax.axis('on')\n","    fig.suptitle('Input FFT Images', fontsize=12)\n","    plt.savefig(os.path.join(project,f'images/img2img_cnn/F6_Images.png'))\n","    plt.show()\n","\n","def create_sequences(data, input_length, label_length):\n","    sequences = []\n","    labels = []\n","    for i in range(len(data) - input_length - label_length):\n","        sequences.append(data[i:(i + input_length)])  # Input sequence\n","        labels.append(data[(i + input_length):(i + input_length + label_length)])  # Label sequence\n","    return np.array(sequences), np.array(labels)\n","\n","\n","def create_cnn_model(input_shape, output_size):\n","    model = Sequential()\n","    model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=input_shape))\n","    model.add(Conv2D(32, kernel_size=3, activation='relu'))\n","    model.add(Flatten())\n","    model.add(Dense(output_size))\n","    return model\n","\n","def plot_predictions_with_input(input_data, actual, predicted):\n","  plt.figure(figsize=(12, 6))\n","\n","  # Select a random index from the test set\n","  idx = np.random.randint(0, actual.shape[0])\n","  print(f'input.shape: {input_data.shape}')\n","\n","  #Inverse tranasforming the values\n","  scaler = full_dataset.get_scaler()\n","  input_inv = scaler.inverse_transform(input_data.reshape(-1, input_data.shape[-1])).reshape(input_data.shape)\n","  actual_inv = scaler.inverse_transform(actual.reshape(-1, actual.shape[-1])).reshape(actual.shape)\n","  predicted_inv = scaler.inverse_transform(predicted.reshape(-1, predicted.shape[-1])).reshape(predicted.shape)\n","\n","\n","  # Inverse FFT to transform input data back to time series\n","  time_series_input = ifft(input_inv[idx]).squeeze().real\n","  print(f'input.shape: {actual.shape}')\n","\n","  # Prepare indices for plotting\n","  input_indices = np.arange(len(time_series_input))\n","  forecast_indices = np.arange(len(time_series_input), len(time_series_input) + len(predicted[idx]))\n","\n","  plt.plot(input_indices, time_series_input[:,idx], label='Input')\n","  plt.plot(forecast_indices, actual_inv[idx,:,idx], label='Actual values', color='green')\n","  plt.plot(forecast_indices, predicted_inv[idx,:,idx], label='Predictions', color='red')\n","  plt.title(f'Prediction for Sequence {idx}')\n","  plt.xlabel('Point in sequence')\n","  plt.ylabel('Value')\n","  plt.legend(loc='best')\n","  plt.savefig(os.path.join(project,f'images/img2img_cnn/F6_{mse:.4f}.png'))\n","  plt.show()\n"]},{"cell_type":"code","source":["df_1 = pd.read_hdf(os.path.join(project, 'src/RICO1_Dataset.hdf'), key='all')\n","\n","full_dataset = RICOFullDataset(data=df_1,\n","                               ori_seq_len=240,\n","                               tgt_seq_len=240,\n","                               stride=1,\n","                               channels=['B.RTD1'],\n","                               standardize=True)\n","\n","dataset_1 = RICODataset(\n","    full_dataset,\n","    kind=\"full\",\n","    get_every=10\n",")\n","\n"],"metadata":{"id":"VR-qAOqmFJ3A","executionInfo":{"status":"ok","timestamp":1703190049510,"user_tz":-60,"elapsed":1012,"user":{"displayName":"Maria Tapia","userId":"08787929203323078025"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# 1. curing data [DONE] return: data w/ shape (102, 24, 1)\n","  # load and sample 10min interval\n","rtd1 = pd.read_csv(os.path.join(project, 'src/rico1_full.tsv'), header=0, usecols=range(1,25))\n","#print(rtd1)\n","rtd1 = rtd1.values\n","#print(rtd1) # (N=102, L=24)\n","train, test = train_test_split(rtd1, test_size=0.2, random_state=42, shuffle=True)\n","print(f'train: {train.shape}, test: {test.shape}')\n","\n","# X_train[0]->y_train[0] , X_train[1]->y_train[1] however, y_train[0] == X_train[1]\n","# grabbing len-forecast number of values as evaluation is based on \"new predictions approach\"\n","# shape (seq_len, batch_size, input_size)\n","rtd1 = torch.from_numpy(rtd1.reshape(rtd1.shape[0], rtd1.shape[1],1))\n","print(f'rtd1.shape:{rtd1.shape}')\n","\n","forecast_horizon = 6\n","inputs, targets = rtd1[:,:-forecast_horizon,:].permute(1,0,2).float(), rtd1[:,-forecast_horizon:,:].permute(1,0,2).float()\n","\n","print(f\"Inputs shape :\", inputs.shape)\n","print(f\"Targets shape :\", targets.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tq4MOzaWFPmG","executionInfo":{"status":"ok","timestamp":1703190220802,"user_tz":-60,"elapsed":4,"user":{"displayName":"Maria Tapia","userId":"08787929203323078025"}},"outputId":"d9d30abc-9602-4f72-e77f-3ea3f0d2a26f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["train: (81, 24), test: (21, 24)\n","rtd1.shape:torch.Size([102, 24, 1])\n","Inputs shape : torch.Size([18, 102, 1])\n","Targets shape : torch.Size([6, 102, 1])\n"]}]},{"cell_type":"code","source":["forecast = 6\n","\n","x, y = create_sequences(rtd1, rtd1.shape[1]-forecast, forecast)\n","\n","# Transform to FFT image\n","x_img = transform_to_image(x)\n","\n","x_train_img, x_test_img, y_train, y_test = train_test_split(x_img, y, test_size=0.2, random_state=42)\n","\n","# Display the first 5 FFT transformed images\n","display_images(x_img[:5])\n","\n","model = create_cnn_model(x_train_img.shape[1:], y_train.shape[1] * y_train.shape[2])\n","model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Training the model\n","model.fit(x_train_img, y_train.reshape(y_train.shape[0], -1), epochs=100, batch_size=16)\n","\n","# Predicting with the test set\n","predictions = model.predict(x_test_img)\n","#print(f'predictions.shape:{predictions.shape}, y_test.shape:{y_test.shape}')\n","\n","# Evaluating the model on the test set\n","mse = mean_squared_error(y_test.reshape(y_test.shape[0], -1), predictions)\n","print(f\"Mean Squared Error: {mse}\")\n","\n","# Reshape y_test to match the predictions shape for plotting\n","predictions = predictions.reshape(y_test.shape[0], y_test.shape[1], y_test.shape[2])\n","\n","# Plotting the first 5 sequences of input, actual values, and predictions\n","plot_predictions_with_input(x_test_img, y_test, predictions)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":491},"id":"NUJKL-F6eWCE","executionInfo":{"status":"error","timestamp":1703190931392,"user_tz":-60,"elapsed":304,"user":{"displayName":"Maria Tapia","userId":"08787929203323078025"}},"outputId":"47fb58da-0402-4c8b-b232-ace97c18ab8f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-11-83c802e0afc5>:28: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n","  return np.array(sequences), np.array(labels)\n","<ipython-input-11-83c802e0afc5>:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  return np.array(sequences), np.array(labels)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-d0445e688848>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Transform to image format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx_train_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-83c802e0afc5>\u001b[0m in \u001b[0;36mtransform_to_image\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtransform_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfft_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfft_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/fft/_backend.py\u001b[0m in \u001b[0;36m__ua_function__\u001b[0;34m(method, args, kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/fft/_pocketfft/basic.py\u001b[0m in \u001b[0;36mc2c\u001b[0;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     15\u001b[0m         raise NotImplementedError('Passing a precomputed plan is not yet '\n\u001b[1;32m     16\u001b[0m                                   'supported by scipy.fft functions')\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asfarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0moverwrite_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverwrite_x\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_datacopied\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/fft/_pocketfft/helper.py\u001b[0m in \u001b[0;36m_asfarray\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'fc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# Require native byte order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"]}]},{"cell_type":"markdown","source":["# Data transformation to images"],"metadata":{"id":"qaIWE3A7HnrW"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","\n","class FFTDataset(Dataset):\n","    def __init__(self, inputs, targets):\n","        self.inputs = inputs\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.inputs)\n","\n","    def __getitem__(self, idx):\n","        return self.inputs[idx], self.targets[idx]\n","\n","class FFTNet(nn.Module):\n","    def __init__(self, input_shape, output_horizon):\n","        super(FFTNet, self).__init__()\n","        self.output_horizon = output_horizon\n","        # Define Convolutional layers\n","        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","\n","        # Compute the size of the features after convolutional layers\n","        conv_output_size = self._get_conv_output(input_shape)\n","\n","        # Define Fully connected layers\n","        self.fc1 = nn.Linear(conv_output_size, 128)\n","        self.fc2 = nn.Linear(128, output_horizon * input_shape[1])\n","\n","    def _get_conv_output(self, shape):\n","        with torch.no_grad():\n","            input = torch.autograd.Variable(torch.rand(1, *shape))\n","            output = self._forward_conv(input)\n","            return int(torch.prod(torch.tensor(output.size())))\n","\n","    def _forward_conv(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.max_pool2d(x, 2)\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2)\n","        x = F.relu(self.conv3(x))\n","        x = F.max_pool2d(x, 2)\n","        return x\n","\n","    def forward(self, x):\n","        x = self._forward_conv(x)\n","        x = x.view(x.size(0), -1)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        x = x.view(-1, self.output_horizon, x.size(1) // self.output_horizon)\n","        return x\n","\n","    def train_model(self, train_loader, optimizer, criterion, num_epochs):\n","        self.train()\n","        for epoch in range(num_epochs):\n","            total_loss = 0\n","            for inputs, targets in train_loader:\n","                optimizer.zero_grad()\n","                outputs = self(inputs)\n","                loss = criterion(outputs, targets)\n","                loss.backward()\n","                optimizer.step()\n","                total_loss += loss.item()\n","            avg_loss = total_loss / len(train_loader)\n","            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n","\n","    def evaluate_model(self, test_loader, criterion):\n","        self.eval()\n","        total_loss = 0\n","        with torch.no_grad():\n","            for inputs, targets in test_loader:\n","                outputs = self(inputs)\n","                loss = criterion(outputs, targets)\n","                total_loss += loss.item()\n","        avg_loss = total_loss / len(test_loader)\n","        return avg_loss\n","\n","    def predict(self, data_loader):\n","        self.eval()\n","        predictions = []\n","        with torch.no_grad():\n","            for inputs in data_loader:\n","                outputs = self(inputs)\n","                predictions.append(outputs.cpu().numpy())\n","        return np.concatenate(predictions)\n","\n","\n","############################################\n","\n","# Creating dataset instances\n","train_dataset = FFTDataset(input_train, target_train)\n","test_dataset = FFTDataset(input_test, target_test)\n","print(f'train_dataset.shape:{len(train_dataset)}, test_dataset.shape:{len(test_dataset)}')\n","\n","#Creating DataLoader instances\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","\n","# Create the model\n","fft_model = FFTNet(train_loader.shape, forecast_horizon)\n","\n","# Define optimizer and loss function\n","optimizer = torch.optim.Adam(fft_model.parameters(), lr=0.001)\n","loss_function = nn.MSELoss()\n","\n","# Train the model\n","fft_model.train_model(train_dataset, optimizer, loss_function, num_epochs=10)\n","\n","# Evaluate the model\n","test_loss = fft_model.evaluate_model(test_loader, loss_function)\n","print(f\"Test Loss: {test_loss:.4f}\")\n","\n","# Predict using the model\n","predictions = fft_model.predict(test_loader)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":268},"id":"GnHGer6x_lsj","executionInfo":{"status":"error","timestamp":1703026799302,"user_tz":-60,"elapsed":415,"user":{"displayName":"Maria Tapia","userId":"08787929203323078025"}},"outputId":"31103b18-c714-42f6-9f88-782f51c3878c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_dataset.shape:18, test_dataset.shape:18\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-cbeb2728935f>\u001b[0m in \u001b[0;36m<cell line: 105>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m# Create the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mfft_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFFTNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast_horizon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# Define optimizer and loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'shape'"]}]}]}